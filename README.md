Our approach was an experimentation: we tried things like removing the outliers by mean of every variables plus to remove the outliers in var1 we predicted the var1 on the linear model and use that value instead of conventional one.plus there were ap and multiplication of 3 , 4 and 0.83 , 0.76 in the data and later use the decision tree prediction with the 2 xg boost model that were giving rmse of approximately 112 we took the harmonic mean of the two xg's model . Might not be the best one but thats all we could think of

112.xx public leaderboard rank 28

94.xx private leaderboard rank 26

Team : Aegis2.0

Team mate : Aman Kapoor &  Anchal Gupta 

Competition Organiser : Analytics Vidhya 
